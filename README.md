# üß† Classifica√ß√£o de Res√≠duos com CNN e Data Augmentation

Este reposit√≥rio apresenta um experimento da disciplina **Fundamentos de Intelig√™ncia Artificial (FIA)** utilizando **Redes Neurais Convolucionais (CNN)** para classificar imagens de res√≠duos em 6 categorias:

`cardboard, glass, metal, paper, plastic, trash`.

Al√©m de treinar um modelo de deep learning, o foco √© **analisar o impacto do data augmentation** na capacidade de generaliza√ß√£o do modelo, avaliando acur√°cia, matriz de confus√£o e comportamento das curvas de treino/valida√ß√£o.

---

## üìÇ Estrutura do Reposit√≥rio

| Arquivo / Pasta | Descri√ß√£o                                                                                                   |
| --------------- | ----------------------------------------------------------------------------------------------------------- |
| `FIA_TP2.ipynb` | Notebook principal com carregamento do dataset, pr√©-processamento, defini√ß√£o do modelo, treinamento e an√°lise. |
| `README.md`     | Documento com o contexto, metodologia, resultados e discuss√£o final do projeto.                             |

---

## üåç Contexto do Problema

A triagem correta de res√≠duos √© um desafio importante em ambientes urbanos e industriais. Separar adequadamente **papel, pl√°stico, vidro, metal, papel√£o e lixo misto** reduz a contamina√ß√£o dos recicl√°veis e aumenta a efici√™ncia de cooperativas e sistemas automatizados.

Neste trabalho, tratamos a triagem como um problema de **classifica√ß√£o de imagens multiclasse**: dada a foto de um res√≠duo, o modelo deve decidir a qual das 6 classes (`cardboard`, `glass`, `metal`, `paper`, `plastic`, `trash`) ela pertence.

O objetivo √© conectar conceitos de IA e vis√£o computacional com uma aplica√ß√£o pr√°tica de sustentabilidade, explorando o uso de CNNs e data augmentation para melhorar o desempenho em um dataset relativamente pequeno e desbalanceado.

---

## üéØ Objetivo

Treinar uma rede neural convolucional capaz de classificar imagens de res√≠duos em 6 classes e:

- Investigar o **efeito do data augmentation** no desempenho;
- Avaliar **overfitting x generaliza√ß√£o** por meio das curvas de treino/valida√ß√£o;
- Analisar, via **matriz de confus√£o**, quais classes s√£o mais confundidas;
- Discutir limita√ß√µes do modelo e poss√≠veis **trabalhos futuros**.

---

## üóÉÔ∏è Dataset

Foi utilizado um dataset p√∫blico do Kaggle derivado do **TrashNet**, contendo imagens em 6 classes:

- `cardboard`
- `glass`
- `metal`
- `paper`
- `plastic`
- `trash`

Principais caracter√≠sticas:

- Aproximadamente alguns milhares de imagens no total;
- Distribui√ß√£o **desbalanceada** entre as classes (por exemplo, `trash` tem bem menos exemplos que `paper` e `plastic`);
- Imagens RGB redimensionadas para **224√ó224** pixels;
- Split feito via `ImageDataGenerator` com `validation_split`, resultando em algo pr√≥ximo de **85% treino / 15% valida√ß√£o**.

No notebook, h√° uma c√©lula que contabiliza a quantidade de imagens em cada pasta e exibe alguns exemplos, evidenciando tanto a **variabilidade visual** quanto o **desbalanceamento** do conjunto de dados.

---

## üß™ Metodologia

### 1. Pr√©-processamento e Data Augmentation

As imagens s√£o carregadas com `ImageDataGenerator` em duas configura√ß√µes:

- **Treino (`train_data`)**
  - `rescale = 1./255`
  - `validation_split` para separar treino/valida√ß√£o
  - Data augmentation **moderado**:
    - `rotation_range = 15`
    - `width_shift_range = 0.1`
    - `height_shift_range = 0.1`
    - `zoom_range = 0.1`
    - `horizontal_flip = True`
    - `fill_mode = 'nearest'`

- **Valida√ß√£o (`val_data`)**
  - Apenas `rescale = 1./255`
  - **Sem augmentation**, para garantir uma avalia√ß√£o mais fiel ao comportamento real do modelo.

Durante o desenvolvimento tamb√©m foram testadas configura√ß√µes de augmentation **mais agressivas** (zoom alto, rota√ß√µes grandes, flips verticais). Essas vers√µes acabaram prejudicando a generaliza√ß√£o, conforme discutido na se√ß√£o de resultados.

---

### 2. Arquitetura da CNN

O modelo implementado segue a ideia proposta no enunciado (blocos convolucionais seguidos de pooling e um classificador denso), mas com capacidade ligeiramente aumentada em rela√ß√£o ao exemplo (mais filtros e uso de ZeroPadding2D):

- **Entrada:** imagem `224√ó224√ó3`, com um `ZeroPadding2D(padding=(1, 1))` para preservar melhor a dimens√£o espacial nas primeiras convolu√ß√µes.
- **Blocos convolucionais + pooling:**
  - `Conv2D(64, 3√ó3, activation='relu')` ‚Üí `Dropout(0.2)` ‚Üí `MaxPool2D(2√ó2)`
  - `Conv2D(128, 3√ó3, activation='relu')` ‚Üí `Dropout(0.2)` ‚Üí `MaxPool2D(2√ó2)`
  - `Conv2D(128, 3√ó3, activation='relu')` ‚Üí `Dropout(0.4)` ‚Üí `MaxPool2D(2√ó2)`
- **Classificador totalmente conectado:**
  - `Flatten()`
  - `Dense(128, activation='relu')`
  - `Dropout(0.5)` para reduzir overfitting
  - `Dense(64, activation='relu')`
  - `Dense(6, activation='softmax')` (uma unidade para cada classe)

Configura√ß√£o de treino:

- **Loss:** `CategoricalCrossentropy`
- **M√©trica:** `CategoricalAccuracy`
- **Otimizador:** `Adam` com `learning_rate = 1e-4`

Callbacks:

- `EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)`
- `ModelCheckpoint` para salvar o melhor modelo durante o treinamento.

---

### 3. Estrat√©gia de Treinamento

- Execu√ß√£o realizada em **GPU (Google Colab)**;
- N√∫mero m√°ximo de √©pocas em torno de **60‚Äì100**, mas na pr√°tica o `EarlyStopping` interrompe quando a valida√ß√£o deixa de melhorar;
- Avalia√ß√£o final feita em cima do conjunto de valida√ß√£o, sem data augmentation, utilizando:
  - acur√°cia,
  - `classification_report`,
  - **matriz de confus√£o**.

---

## üìä Resultados

Os n√∫meros abaixo correspondem √† melhor execu√ß√£o utilizando o notebook de refer√™ncia (aquele que obteve a melhor combina√ß√£o de acur√°cia e matriz de confus√£o):

- **Acur√°cia de treino:** ~**65%**
- **Acur√°cia de valida√ß√£o:** ~**~57%**  
  (248 acertos em 377 imagens no conjunto de valida√ß√£o)

### Desempenho por classe (valida√ß√£o)

A partir da matriz de confus√£o:

- `cardboard`: ‚âà 62% de recall (37/60)
- `glass`: ‚âà 52% de recall (39/75)
- `metal`: ‚âà 74% de recall (45/61)
- `paper`: ‚âà 87% de recall (77/89)
- `plastic`: ‚âà 22% de recall (16/72)
- `trash`: ‚âà 5% de recall (1/20)

O modelo tem desempenho muito bom em `paper` e `metal`, razo√°vel em `cardboard` e `glass`, e encontra mais dificuldade em `plastic` e, principalmente, `trash`. A classe `trash` possui poucos exemplos e √© muito heterog√™nea, o que explica o baixo recall e as confus√µes com `metal`, `paper` e `glass`.

---

### üìà Curvas de Treino e Valida√ß√£o

![Gr√°fico de Treinamento](grafico_acuracia.png)

O gr√°fico de acur√°cia mostra que:

- As acur√°cias de treino e valida√ß√£o **aumentam ao longo das √©pocas**;
- O treino atinge cerca de **71%** e a valida√ß√£o estabiliza em torno de **60‚Äì66%**;
- H√° um *gap* moderado entre as curvas (~0.06‚Äì0.1), indicando algum **overfitting leve**, esperado em datasets pequenos, mas **sem colapso**: a valida√ß√£o n√£o despenca, o que indica boa capacidade de generaliza√ß√£o.

---

### üßÆ Matriz de Confus√£o

![Matriz de Confus√£o](matriz_confusao.png)

A matriz de confus√£o evidencia que:

- `paper`, `metal`, `glass` e `cardboard` concentram grande parte dos acertos na diagonal;
- `plastic` √© frequentemente confundido com `paper` e `glass` (por exemplo, garrafas pl√°sticas x garrafas de vidro);
- `trash` √© confundido com `metal`, `paper` e `plastic`, o que faz sentido por ser uma classe mais **gen√©rica e heterog√™nea** e com menor n√∫mero de exemplos.

---

---

## üß† An√°lise da Generaliza√ß√£o e Erros

- Classes mais confundidas:

  > Lixo Org√¢nico (trash): Esta foi a classe com o desempenho mais baixo (recall de $\approx 40\%$). O modelo teve dificuldade em identificar corretamente os itens desta categoria.
  > Pl√°stico (plastic): Foi a segunda classe mais dif√≠cil, com um recall de $\approx 57\%$.
  
- Poss√≠veis causas:

  - Semelhan√ßa visual entre classes: A principal confus√£o provavelmente ocorre entre plastic e glass (vidro), j√° que ambos podem ser transparentes e ter formatos de garrafa, tornando-os dif√≠ceis de distinguir para a CNN.
  - Dataset desbalanceado: A classe trash √© a menor de todo o dataset. Mesmo com o uso de class_weight (que ajudou muito), o modelo ainda teve menos exemplos para aprender os padr√µes dessa classe, o que explica seu baixo recall.
  - Limita√ß√µes da arquitetura: Embora o modelo tenha atingido 71%, ele ainda √© uma CNN personalizada. Classes muito complexas ou com poucas amostras podem exigir arquiteturas mais profundas (como as de Transfer Learning) para uma classifica√ß√£o perfeita.

---

## üîÅ Impacto do Data Augmentation

Durante o projeto foram testados tr√™s cen√°rios principais:

1. **Sem data augmentation**  
   - O modelo aprendia r√°pido no conjunto de treino, mas a acur√°cia de valida√ß√£o ficava em torno de **0.40‚Äì0.45**;  
   - As curvas mostravam **overfitting**, com a acur√°cia de treino subindo bem mais que a de valida√ß√£o.

2. **Data augmentation muito agressivo**  
   - Foram aplicadas rota√ß√µes muito grandes, zooms fortes e flips verticais;  
   - O modelo teve dificuldade para convergir e passou a confundir quase todas as classes, muitas vezes prevendo majoritariamente `plastic`;  
   - A acur√°cia de valida√ß√£o caiu para valores pr√≥ximos de **0.25‚Äì0.30**, mostrando que transforma√ß√µes exageradas podem **distorcer demais o padr√£o visual** dos res√≠duos.

3. **Data augmentation moderado (configura√ß√£o final)**  
   - Rota√ß√µes menores, shifts e zoom leves e apenas flip horizontal;  
   - A acur√°cia de valida√ß√£o subiu para cerca de **0.60‚Äì0.66**;  
   - As curvas de treino/valida√ß√£o ficaram mais est√°veis e a matriz de confus√£o passou a mostrar acertos bem distribu√≠dos entre as classes.

**Conclus√£o:** o data augmentation √© fundamental nesse problema, mas precisa ser **calibrado**. Com augmentations moderados, o modelo aprende melhor, reduz overfitting e generaliza bem para imagens nunca vistas.

---

## üîç Limita√ß√µes

Limita√ß√µes observadas:

- **Dataset pequeno e desbalanceado**, principalmente para a classe `trash`;
- **Semelhan√ßa visual** entre `plastic`, `glass` e `paper`, o que gera confus√µes frequentes;
- Arquitetura ainda relativamente simples se comparada a modelos de estado da arte.

---

## ‚öôÔ∏è Tecnologias Utilizadas

- Python  
- TensorFlow / Keras  
- NumPy / Pandas  
- Matplotlib / Seaborn  
- Jupyter Notebook  
- Google Colab (GPU)

---

## üë• Alunos

- Yago Lobato ‚Äî yagobrlobato@icomp.ufam.edu.br  
- Nath√£ Barbosa ‚Äî NathaBarbosa@icomp.ufam.edu.br  
- Matheus Santar√©m ‚Äî matheus.santarem@icomp.ufam.edu.br  
- Emanuel Andriola ‚Äî Emanuel.moraes@icomp.ufam.edu.br  
- Daniel Trindade ‚Äî daniel.trindade@icomp.ufam.edu.br  
- Cristiano Cardoso ‚Äî cristiano.lima@icomp.ufam.edu.br
