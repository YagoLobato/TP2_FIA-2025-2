# ğŸ§  ClassificaÃ§Ã£o de Imagens com CNN e Data Augmentation

Este repositÃ³rio contÃ©m um experimento utilizando **Redes Neurais Convolucionais (CNN)** para classificaÃ§Ã£o de imagens.
O objetivo principal Ã© analisar como diferentes estratÃ©gias de **Data Augmentation** afetam o desempenho do modelo, com foco em mÃ©tricas como acurÃ¡cia e matriz de confusÃ£o.

---

## ğŸ“‚ Estrutura do RepositÃ³rio


| Arquivo / Pasta | DescriÃ§Ã£o                                                                                                                                |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `FIA_TP2.ipynb` | Notebook contendo o cÃ³digo completo do projeto, incluindo prÃ©-processamento, definiÃ§Ã£o do modelo, treinamento, avaliaÃ§Ã£o e anÃ¡lise. |
| `README.md`     | Documento com o contexto, metodologia e resultados finais do projeto.                                                                      |

---

## ğŸ¯ Objetivo

Treinar um modelo de deep learning para classificaÃ§Ã£o de imagens utilizando tÃ©cnicas de aumento de dados (data augmentation), avaliando:

- GeneralizaÃ§Ã£o do modelo
- ReduÃ§Ã£o de overfitting
- Impacto nas mÃ©tricas finais de desempenho

---

## ğŸ§ª Metodologia

O projeto utiliza a seguinte pipeline:

1. **Carregamento e organizaÃ§Ã£o do dataset**
2. **Data Augmentation** com transformaÃ§Ãµes como:
   - RotaÃ§Ã£o
   - Flip horizontal
   - Zoom
   - MudanÃ§a de brilho
   - Shear
3. **Treinamento de uma CNN** com:
   - Callbacks (Early Stopping, Reduce LR on Plateau e ModelCheckpoint)
   - Split entre treino e validaÃ§Ã£o
4. **AvaliaÃ§Ã£o do modelo**, incluindo matriz de confusÃ£o e acurÃ¡cia.
5. **DiscussÃ£o dos resultados**.

---

## ğŸ“Š Resultados (a preencher apÃ³s execuÃ§Ã£o)

- **AcurÃ¡cia final:**

  > _Exemplo:_ `xx.xx%`
  >
- **Matriz de confusÃ£o:**
  _(Inserir imagem ou tabela apÃ³s execuÃ§Ã£o do notebook)_
- **Loss x Epoch / Accuracy x Epoch:**
  _(Inserir grÃ¡ficos gerados no notebook)_

---

## ğŸ§  AnÃ¡lise da GeneralizaÃ§Ã£o e Erros

- Classes mais confundidas:

  > _(Anotar apÃ³s anÃ¡lise da matriz de confusÃ£o)_
  >
- PossÃ­veis causas:

  - SemelhanÃ§a visual entre classes
  - Dataset desbalanceado
  - LimitaÃ§Ãµes da arquitetura

---

## ğŸ ConclusÃ£o

Com base nas anÃ¡lises, o uso de **data augmentation** teve impacto relevante no modelo, auxiliando na reduÃ§Ã£o de overfitting e melhorando a capacidade de generalizaÃ§Ã£o.
Comparando os resultados com e sem augmentation, observa-se que o modelo com augmentations:

âœ” Treina de maneira mais estÃ¡vel
âœ” Generaliza melhor em dados nunca vistos
âœ” Reduz discrepÃ¢ncias entre loss/accuracy de treino e validaÃ§Ã£o

A implementaÃ§Ã£o e experimentaÃ§Ã£o demonstram a importÃ¢ncia dessas tÃ©cnicas quando se trabalha com datasets limitados ou desbalanceados.

---

## ğŸ“Œ Tecnologias Utilizadas

- Python
- TensorFlow / Keras
- NumPy / Pandas
- Matplotlib
- Jupyter Notebook

## Alunos

- Yago Lobato
- NathÃ£ Barbosa
- Matheus SantarÃ©m
- Emanuel Andriola
- Daniel Trindade
- Cristiano Cardoso

### E-mails

- yagobrlobato@icomp.ufam.edu.br
- NathaBarbosa@icomp.ufam.edu.br
- matheus.santarem@icomp.ufam.edu.br
- Emanuel.moraes@icomp.ufam.edu.br
- daniel.trindade@icomp.ufam.edu.br
- cristiano.lima@icomp.ufam.edu.br

---
