# üß† Classifica√ß√£o de Imagens com CNN e Data Augmentation

Este reposit√≥rio cont√©m um experimento utilizando **Redes Neurais Convolucionais (CNN)** para classifica√ß√£o de imagens.
O objetivo principal √© analisar como diferentes estrat√©gias de **Data Augmentation** afetam o desempenho do modelo, com foco em m√©tricas como acur√°cia e matriz de confus√£o.

---

## üìÇ Estrutura do Reposit√≥rio


| Arquivo / Pasta | Descri√ß√£o                                                                                                                                |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `FIA_TP2.ipynb` | Notebook contendo o c√≥digo completo do projeto, incluindo pr√©-processamento, defini√ß√£o do modelo, treinamento, avalia√ß√£o e an√°lise. |
| `README.md`     | Documento com o contexto, metodologia e resultados finais do projeto.                                                                      |

---

## üéØ Objetivo

Treinar um modelo de deep learning para classifica√ß√£o de imagens utilizando t√©cnicas de aumento de dados (data augmentation), avaliando:

- Generaliza√ß√£o do modelo
- Redu√ß√£o de overfitting
- Impacto nas m√©tricas finais de desempenho

---

## üß™ Metodologia

O projeto utiliza a seguinte pipeline:

1. **Carregamento e organiza√ß√£o do dataset**
2. **Data Augmentation** com transforma√ß√µes como:
   - Rota√ß√£o
   - Flip horizontal
   - Zoom
   - Mudan√ßa de brilho
   - Shear
3. **Treinamento de uma CNN** com:
   - Callbacks (Early Stopping, Reduce LR on Plateau e ModelCheckpoint)
   - Split entre treino e valida√ß√£o
4. **Avalia√ß√£o do modelo**, incluindo matriz de confus√£o e acur√°cia.
5. **Discuss√£o dos resultados**.

---

üìä Resultados

O modelo atingiu um desempenho satisfat√≥rio considerando a complexidade do dataset.

* **Acur√°cia final:** 71% (0.71)

#### Hist√≥rico de Treinamento (Acur√°cia e Loss)
![Gr√°fico de Treinamento](grafico_acuracia.png)
*O gr√°fico demonstra a estabilidade do treinamento e a redu√ß√£o do overfitting gra√ßas ao Data Augmentation.*

#### Matriz de Confus√£o
![Matriz de Confus√£o](matriz_confusao.png)

*A matriz indica que o modelo tem excelente desempenho em Papel e Papel√£o, com melhorias significativas na detec√ß√£o de Pl√°stico e Lixo org√¢nico na vers√£o final.*

---

## üß† An√°lise da Generaliza√ß√£o e Erros

- Classes mais confundidas:

  > Lixo Org√¢nico (trash): Esta foi a classe com o desempenho mais baixo (recall de $\approx 40\%$). O modelo teve dificuldade em identificar corretamente os itens desta categoria.
  > Pl√°stico (plastic): Foi a segunda classe mais dif√≠cil, com um recall de $\approx 57\%$.
  
- Poss√≠veis causas:

  - Semelhan√ßa visual entre classes: A principal confus√£o provavelmente ocorre entre plastic e glass (vidro), j√° que ambos podem ser transparentes e ter formatos de garrafa, tornando-os dif√≠ceis de distinguir para a CNN.
  - Dataset desbalanceado: A classe trash √© a menor de todo o dataset. Mesmo com o uso de class_weight (que ajudou muito), o modelo ainda teve menos exemplos para aprender os padr√µes dessa classe, o que explica seu baixo recall.
  - Limita√ß√µes da arquitetura: Embora o modelo tenha atingido 71%, ele ainda √© uma CNN personalizada. Classes muito complexas ou com poucas amostras podem exigir arquiteturas mais profundas (como as de Transfer Learning) para uma classifica√ß√£o perfeita.

---

## üèÅ Conclus√£o

Com base nas an√°lises, o uso de **data augmentation** teve impacto relevante no modelo, auxiliando na redu√ß√£o de overfitting e melhorando a capacidade de generaliza√ß√£o.
Comparando os resultados com e sem augmentation, observa-se que o modelo com augmentations:

‚úî Treina de maneira mais est√°vel
‚úî Generaliza melhor em dados nunca vistos
‚úî Reduz discrep√¢ncias entre loss/accuracy de treino e valida√ß√£o

A implementa√ß√£o e experimenta√ß√£o demonstram a import√¢ncia dessas t√©cnicas quando se trabalha com datasets limitados ou desbalanceados.

---

## üìå Tecnologias Utilizadas

- Python
- TensorFlow / Keras
- NumPy / Pandas
- Matplotlib
- Jupyter Notebook

## Alunos

- Yago Lobato
- Nath√£ Barbosa
- Matheus Santar√©m
- Emanuel Andriola
- Daniel Trindade
- Cristiano Cardoso

### E-mails

- yagobrlobato@icomp.ufam.edu.br
- NathaBarbosa@icomp.ufam.edu.br
- matheus.santarem@icomp.ufam.edu.br
- Emanuel.moraes@icomp.ufam.edu.br
- daniel.trindade@icomp.ufam.edu.br
- cristiano.lima@icomp.ufam.edu.br

---
